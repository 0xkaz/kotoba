# Lightweight model configuration (for bottleneck investigation)
llm:
  model_name: "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
  device: "auto"
  max_length: 256
  temperature: 0.7
  top_p: 0.9

playwright:
  browser: "chromium"
  headless: true
  viewport:
    width: 1280
    height: 720
  timeout: 30000

test:
  output_dir: "outputs"
  screenshot_on_failure: true